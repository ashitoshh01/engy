claude-3-5-sonnet-20240620

You are Claude, an AI assistant powered by Anthropic's Claude-3.5-Sonnet model, specialized in software development.
You are a software designer.
Your job to design an app. The app is usually very simple and can be always expressed in a python web server backend plus a single html page frontend.
The given input is the app description.
Use your imagination to design a fancy app with only one python server (backend) with only one html page (frontend). 

The output backend design should be in <BACKEND_DESIGN></BACKEND_DESIGN> block.
The output frontend design should be in <FRONTEND_DESIGN></FRONTEND_DESIGN> block.
There should be exactly one <BACKEND_DESIGN> and one <FRONTEND_DESIGN>.


=== 0: user ===
# The app description:
```
Build my personal research agent.

I can type a person name, the agent search on internet.

Result is rendered in a sophicated UI below containing a person's basic information e.g. Name, Occupation, Company. and email address.

The UI also need to show steplog in real time.
```

## Here is code example when building agent:
```

from crewai import Agent, Crew, Task
from langchain_core.agents import AgentFinish
from crewai_tools import ScrapeWebsiteTool, SerperDevTool
from langchain_anthropic import ChatAnthropic

os.environ["ANTHROPIC_API_KEY"] = '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'

# model = 'claude-3-haiku-20240307'
model = 'claude-3-5-sonnet-20240620'

# ...

search_icp = 'US based companies, ~20-200 employees, Seed - Series B'
seed_search_query = 'Find 10 such companies, ideally in the software/tech space.'

def step_callback(step_output):
    step_outputs.append(step_output)
    with open('step_outputs.pickle', 'wb') as f:
        pickle.dump(step_outputs, f)

    global step_outputs_timestamp
    step_outputs_timestamp = datetime.datetime.now()


def create_crew(input_search_icp, input_seed_search_query):
    search_tool = SerperDevTool()
    scrape_tool = ScrapeWebsiteTool()

    contact_finder = Agent(
        role='Comanpy Seacher',
        goal='Search qualified company based on given comapny ICP (Idea Customer Profile)',
        backstory="""You are an expert in company searching industry. You are good at just by searching through public internet like scraping company official site, related news articles to find out relevant contacts.""",
        verbose=True,
        allow_delegation=False,
        # You can pass an optional llm attribute specifying what model you wanna use.
        llm=ChatAnthropic(model=model, temperature=0.9),
        tools=[search_tool]
    )

    sales = Agent(
        role='Senior Sales Representative',
        goal='Search internet and major social websites and find out given person contact information',
        backstory="""You work at a startup as a sales. You are farmilier with major social websites and good finding and contacting people.""",
        verbose=True,
        allow_delegation=False,
        # You can pass an optional llm attribute specifying what model you wanna use.
        llm=ChatAnthropic(model=model, temperature=0.9),
        tools=[search_tool, scrape_tool]
    )

    task1 = Task(
        description=f"""1. Search ICP: {input_search_icp}
2. Seed search query: {input_seed_search_query}

Based on "search ICP", use "seed search query" in search tool to list some qualified companies in CSV format.
You may try different variation queries to populate a diverse list.

You can infer "country", "employee_numbers" and "fundraise_round" from the search results.
""",
        expected_output="""Return in CSV format with exact header [company_full_name, official_website, country, employee_numbers, fundraise_round]

The output must follow:
```csv
company_full_name, official_website, country, employee_numbers, fundraise_round
...
...
```
    """,
        agent=contact_finder
    )

    task2 = Task(
        description="""Find one contact for each of these comapnies.
Contacts are better titles of Finance, Operations and Revenue Operations as well as Founder(s), CEO.

If you can find their linkedin page URL, also add to the table.
""",
    expected_output="""Return in CSV format with exact header [first_name, last_name, job_title, company_full_name, official_website, linkedin_page]

The output must follow:
```csv
first_name, last_name, job_title, company_full_name, official_website, linkedin_page
...
...
```
    """,
        agent=sales
    )

    task3 = Task(
        description="""Try best to search and make up contact's "email address".

You may:
1. Do more search using search tool.
2. Scraping their personal_website
3. Scraping company official_website.
4. Don't scrape linkedin page (since the site is blocked).

If not found, try best to make up one, e.g. {first_name}{last_name}@gmail.com        
""",
    expected_output="""Return in CSV format with exact header [first_name, last_name, job_title, email_address, linkedin_page, personal_website, company_full_name, official_website]

The output must follow:
```csv
first_name, last_name, job_title, email_address, linkedin_page, personal_website, company_full_name, official_website
...
...
```
    """,
        agent=sales
    )

    # Instantiate your crew with a sequential process
    crew = Crew(
        agents=[contact_finder, sales],
        tasks=[task1, task2, task3],
        step_callback=step_callback,
        verbose=2,  # You can set it to 1 or 2 to different logging levels
        output_log_file='1.log',
    )
    return crew


def run_agent(input_search_icp, input_seed_search_query):
    global step_outputs
    step_outputs = []

    crew = create_crew(input_search_icp, input_seed_search_query)
    result = crew.kickoff()
    print("###################### Result:")
    print(result)

```

Based on given app description, generate <BACKEND_DESIGN> and <FRONTEND_DESIGN>.
<BACKEND_DESIGN> will be written in "backend_design.txt".
<FRONTEND_DESIGN> will be written in "frontend_design.txt".


=== Reply 0 ===
Here's my design for the personal research agent app based on your description:

<BACKEND_DESIGN>
The backend will be a Python Flask server with the following components:

1. Main Flask app:
   - Handles routing and API endpoints
   - Initializes the CrewAI agents and tasks

2. Research Agent:
   - Uses CrewAI to create agents for searching and scraping information
   - Implements the following agents:
     a. PersonSearcher: Searches for basic information about the person
     b. ContactFinder: Finds email addresses and additional details

3. API Endpoints:
   - POST /search: Accepts a person's name, triggers the research process
   - GET /status: Returns the current status and step logs of the research process

4. Websocket:
   - Implements real-time updates for step logs

5. Data Storage:
   - In-memory storage for search results and step logs
   - Option to persist data to a lightweight database like SQLite

6. Error Handling:
   - Graceful error handling for API requests and agent operations

The server will use the CrewAI library to create and manage agents, similar to the provided example code. It will adapt the agents and tasks to focus on person-specific research instead of company searches.
</BACKEND_DESIGN>

<FRONTEND_DESIGN>
The frontend will be a single HTML page with embedded JavaScript and CSS. It will have the following components:

1. Header:
   - Title: "Personal Research Agent"
   - Subtitle: "Enter a person's name to start research"

2. Search Section:
   - Input field for person's name
   - Search button

3. Results Display:
   - Initially hidden, shown after search completes
   - Sections for:
     a. Basic Information (Name, Occupation, Company)
     b. Contact Information (Email address)
   - Styled with a modern, card-based layout

4. Real-time Step Log:
   - Scrollable area showing step-by-step progress
   - Auto-scrolls to the bottom as new steps are added
   - Styled to look like a terminal/console

5. Status Indicator:
   - Shows current status (e.g., "Searching", "Complete", "Error")

6. Responsive Design:
   - Adapts to different screen sizes (desktop, tablet, mobile)

7. JavaScript Functionality:
   - Handles form submission
   - Makes API calls to the backend
   - Updates the UI with search results
   - Manages WebSocket connection for real-time updates

8. CSS Styling:
   - Modern, clean design with a color scheme that's easy on the eyes
   - Animations for loading states and transitions

The frontend will use vanilla JavaScript for simplicity, but could be easily adapted to a framework like Vue.js or React for more complex functionality if needed in the future.
</FRONTEND_DESIGN>